{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4s5Qf21VwpwrXHe14KIDN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Quantization and Pruning"],"metadata":{"id":"8i_rQSdU9dhX"}},{"cell_type":"markdown","source":["This notebook will cover mobile optimization techniques quantization and pruning. These techniques enable reduced model size and latency whic make it ideal for edge and IOT devices."],"metadata":{"id":"QFXVrNxx9-0-"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ESyIORTf6Y9B","executionInfo":{"status":"ok","timestamp":1723153685896,"user_tz":-120,"elapsed":10002,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import tempfile\n","import zipfile"]},{"cell_type":"code","source":["# GLOBAL VARIABLES\n","\n","# String constants for model filenames\n","FILE_WEIGHTS = 'baseline.weights.h5'\n","FILE_NON_QUANTIZED_H5 = 'non_quantized.h5'\n","FILE_NON_QUANTIZED_TFLITE = 'non_quantized.tflite'\n","FILE_PT_QUANTIZED = 'post_training_quantized.tflite'\n","FILE_QAT_QUANTIZED = 'quant_aware_quantized.tflite'\n","FILE_PRUNED_MODEL_H5 = 'pruned_model.h5'\n","FILE_PRUNED_QUANTIZED_TFLITE = 'pruned_quantized.tflite'\n","FILE_PRUNED_NON_QUANTIZED_TFLITE = 'pruned_non_quantized.tflite'"],"metadata":{"id":"2_GBHQ1T6lZT","executionInfo":{"status":"ok","timestamp":1723154052308,"user_tz":-120,"elapsed":404,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Dictionaries to hold measurements\n","MODEL_SIZE = {}\n","ACCURACY = {}"],"metadata":{"id":"MpFfIkK26rql","executionInfo":{"status":"ok","timestamp":1723153805722,"user_tz":-120,"elapsed":2,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def print_metrics(metric_dict, metric_name):\n","  '''Prints key and values stored in a dictionary'''\n","  for metric, value in metric_dict.items():\n","    print(f'{metric_name} for {metric}: {value}')\n","\n","\n","def model_builder():\n","  '''Returns a CNN for training on MNIST dataset'''\n","\n","  keras = tf.keras\n","\n","  # Define the model architecture\n","  model = keras.Sequential([\n","      keras.layers.InputLayer(shape=(28,28)),\n","      keras.layers.Reshape(target_shape=(28,28,1)),\n","      keras.layers.Conv2D(filters=12, kernel_size=(3,3), activation='relu'),\n","      keras.layers.MaxPooling2D(pool_size=(2,2)),\n","      keras.layers.Flatten(),\n","      keras.layers.Dense(units=10, activation='softmax')\n","  ])\n","\n","  return model\n","\n","\n","def evaluate_tflite_model(filename, x_test, y_test):\n","  '''\n","  Measures accuracy of a given TF Lite model on test set\n","\n","  Args:\n","    filename: path to the TF Lite model\n","    x_test (numpy array): test images\n","    y_test (numpy array): test labels\n","\n","  Returns:\n","    accuracy: accuracy of the model\n","  '''\n","\n","  # Initialize the TF lite Interpreter and allocate tensors\n","  interpreter = tf.lite.Interpreter(model_path=filename)\n","  interpreter.allocate_tensors()\n","\n","  # Get input and output tensors\n","  input_index = interpreter.get_input_details()[0]['index']\n","  output_index = interpreter.get_output_details()[0]['index']\n","\n","  # Initialize empty predictions list\n","  prediction_digits = []\n","\n","  # Run predictions on every image in the \"test\" dataset.\n","  for i, test_image in enumerate(x_test):\n","    # Preprocessing: add batch dimension and convert to float32 to match with the models input data format.\n","    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n","    interpreter.set_tensor(input_index, test_image)\n","\n","    # Run inference\n","    interpreter.invoke()\n","\n","    # Postprocessing: remove batch dimension and find the digit with highest probability.\n","    output = interpreter.tensor(output_index)\n","    digit = np.argmax(output()[0])\n","    prediction_digits.append(digit)\n","\n","  prediction_digits = np.array(prediction_digits)\n","  accuracy = (prediction_digits == y_test).mean()\n","\n","  return accuracy\n","\n","def get_gzipped_model_size(file):\n","  '''Return size of gzipped model in bytes.'''\n","  _, zipped_file = tempfile.mkstemp('.zip')\n","  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(file)\n","\n","  return os.path.getsize(zipped_file)"],"metadata":{"id":"6SrV4Kbw7AFG","executionInfo":{"status":"ok","timestamp":1723154187277,"user_tz":-120,"elapsed":1,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Load MNIST dataset\n","mnist = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalize the input image so that each pixel value is in [0,1] range.\n","x_train, x_test = x_train / 255.0, x_test / 255."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xwI81JFK-CZz","executionInfo":{"status":"ok","timestamp":1723153887716,"user_tz":-120,"elapsed":2262,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"74a85db5-7bf7-41ce-858f-94e7694147d3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["# Create the baseline model\n","baseline_model = model_builder()\n","\n","# Save the initial weights for later use\n","baseline_model.save_weights(FILE_WEIGHTS)\n","\n","# Print the model summary\n","baseline_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"9LQ90ivL-VTw","executionInfo":{"status":"ok","timestamp":1723154077640,"user_tz":-120,"elapsed":415,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"9b40cec4-273e-4ffa-a8ac-d3725ea7de6b"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_3\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │             \u001b[38;5;34m120\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2028\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │          \u001b[38;5;34m20,290\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2028</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,290</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,410\u001b[0m (79.73 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,410</span> (79.73 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,410\u001b[0m (79.73 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,410</span> (79.73 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# Setup the model for training\n","baseline_model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Train the model\n","baseline_model.fit(x_train, y_train, epochs=1, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwOpAp6D-rkZ","executionInfo":{"status":"ok","timestamp":1723154136960,"user_tz":-120,"elapsed":20867,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"ba493dda-1f08-4580-d899-19eaa2732a29"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8656 - loss: 0.5122\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a9459c84bb0>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Get the baseline accuracy\n","_, ACCURACY['baseline Keras model'] = baseline_model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jH0GFpj-1Vm","executionInfo":{"status":"ok","timestamp":1723154160936,"user_tz":-120,"elapsed":3100,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"19187600-cd12-4cf7-bd34-272881a0b3d5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9520 - loss: 0.1616\n"]}]},{"cell_type":"code","source":["# Save the keras model\n","baseline_model.save(FILE_NON_QUANTIZED_H5, include_optimizer=False)\n","\n","# Save and get the model size\n","MODEL_SIZE['baseline h5'] = os.path.getsize(FILE_NON_QUANTIZED_H5)\n","\n","# Print records so far\n","print_metrics(ACCURACY, 'Accuracy')\n","print_metrics(MODEL_SIZE, 'Model size')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZdxRW22_A74","executionInfo":{"status":"ok","timestamp":1723154194125,"user_tz":-120,"elapsed":401,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"35e9bbe2-46a5-4cf4-d99e-4829d9402d96"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Accuracy for baseline Keras model: 0.9595000147819519\n","Model size for baseline h5: 100992\n"]}]},{"cell_type":"markdown","source":["\n","\n","Next, we will convert the model to Tensorflow Lite (TF Lite) format. This is designed to make Tensorflow models more efficient and lightweight when running on mobile, embedded and IOT devices."],"metadata":{"id":"rCryZSo7Aqlz"}},{"cell_type":"code","source":["def convert_tflite(model, filename, quantize=False):\n","  '''\n","  Convert the model to TF Lite format and write to a file\n","\n","  Args:\n","    model (Keras model): model to convert\n","    filename (str): path to write\n","    quantize (bool): whether to quantize the model\n","\n","  Returns:\n","    None\n","  '''\n","\n","  # Initialize the converter\n","  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","\n","  # Set for quantization if flag is True\n","  if quantize:\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","\n","  # Convert the model\n","  tflite_model = converter.convert()\n","\n","  # Save the model\n","  with open(filename, 'wb') as f:\n","    f.write(tflite_model)"],"metadata":{"id":"eFV6Ko-F_aq1","executionInfo":{"status":"ok","timestamp":1723154298045,"user_tz":-120,"elapsed":409,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Convert baseline model\n","convert_tflite(baseline_model, FILE_NON_QUANTIZED_TFLITE)"],"metadata":{"id":"mz1tvWcVAq1g","executionInfo":{"status":"ok","timestamp":1723154377467,"user_tz":-120,"elapsed":921,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ef7c500-b7bf-49f8-b8c5-3d31aabcf238"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmp0b5qa70v'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='keras_tensor_18')\n","Output Type:\n","  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n","Captures:\n","  134777580069536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134777580073056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134777580072704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  134777580074816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]}]},{"cell_type":"code","source":["MODEL_SIZE['non quantized tflite'] = os.path.getsize(FILE_NON_QUANTIZED_TFLITE)\n","\n","print_metrics(MODEL_SIZE, 'model size in bytes')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NUY9-_5Au6l","executionInfo":{"status":"ok","timestamp":1723154577775,"user_tz":-120,"elapsed":390,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"e3077e50-99ad-448b-b749-a993f42d2bb5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["model size in bytes for baseline h5: 100992\n","model size in bytes for non quantized tflite: 84912\n"]}]},{"cell_type":"markdown","source":["There is already a slight decrease in model size when converting to '.tflite' format. The accuracy will also be almost identical between these two."],"metadata":{"id":"Z2PBBs8mBK8b"}},{"cell_type":"code","source":["ACCURACY['non quantized tflite'] = evaluate_tflite_model(FILE_NON_QUANTIZED_TFLITE, x_test, y_test)\n","\n","print_metrics(ACCURACY, 'test accuracy')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsHrkMjQA-gV","executionInfo":{"status":"ok","timestamp":1723154984326,"user_tz":-120,"elapsed":483,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"a874a7a5-ad3d-43a4-c2c6-1ac076f5d935"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy for baseline Keras model: 0.9595000147819519\n","test accuracy for non quantized tflite: 0.9595\n"]}]},{"cell_type":"code","source":["# Convert and quantize the baseline model\n","convert_tflite(baseline_model, FILE_PT_QUANTIZED, quantize=True)"],"metadata":{"id":"kkVIdYR7BJpg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that you we have the baseline metrics, we can observe the effects of quantization. This process involves converting floating point representations into integer to reduce model size and achieve faster computation."],"metadata":{"id":"dgUWkOXyCRcJ"}},{"cell_type":"code","source":["# Get the model size\n","MODEL_SIZE['post training quantized tflite'] = os.path.getsize(FILE_PT_QUANTIZED)\n","\n","print_metrics(MODEL_SIZE, 'model size in bytes')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmnWBkAMBfEp","executionInfo":{"status":"ok","timestamp":1723154834498,"user_tz":-120,"elapsed":419,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"d9be814a-ef1f-4d92-db1f-77520b3caf20"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["model size in bytes for baseline h5: 100992\n","model size in bytes for non quantized tflite: 84912\n","model size in bytes for post training quantized tflite: 24264\n"]}]},{"cell_type":"markdown","source":["We can see that there is around 4X reduction in model size with quantized version. This comes from converting the 32 bit representations (floats) to 8 bits (integer). Also, accuracy stays almost the same in this case. You can expect it to be lower usually but in some cases it can even increase."],"metadata":{"id":"l_hHE5sCCwuD"}},{"cell_type":"code","source":["ACCURACY['post training quantized tflite'] = evaluate_tflite_model(FILE_PT_QUANTIZED, x_test, y_test)\n","\n","print_metric(ACCURACY, 'test accuracy')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y6Wa58V7Bo8O","executionInfo":{"status":"ok","timestamp":1723155074464,"user_tz":-120,"elapsed":399,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"87d47526-5785-400b-d746-cfb29c33d1b6"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["test accuracy for baseline Keras model: 0.9595000147819519\n","test accuracy for non quantized tflite: 0.9595\n","test accuracy for post training quantized tflite: 0.9596\n"]}]},{"cell_type":"code","source":["!pip install tensorflow_model_optimization"],"metadata":{"id":"Ix2kaKrcBtgZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Another technique for reducing model size is Pruning. This process involves zeroing out isignificant (i.e. low magnitude) weights. Idea is that these weights do not contribute that much to making predictions so we can remove them and get the same results. Making the weights sparse helps is compressing the model more efficiently.\n","\n","The Tensorflow Model Optimization Toolkit again has a convenience method for this. The prune_low_magnitude() method puts wrappers in a Keras model so it can be pruned during training. We will pass in the baseline model that we already trained earlier. We will notice that the model summary show increased params because of the wrapper layers added by the pruning method."],"metadata":{"id":"B_4cfUIlFEvM"}},{"cell_type":"code","source":["# Get the pruning method\n","import tensorflow_model_optimization as tfmot\n","\n","prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","\n","# Compute end step to finish pruning after 2 epochs.\n","batch_size=128\n","epochs=2\n","validation_split=0.1\n","\n","num_images = x_train.shape[0] * (1 - validation_split)\n","end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","\n","# Define pruning schedule\n","pruning_params = {\n","    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n","                                                             final_sparsity=0.80,\n","                                                             begin_step=0,\n","                                                             end_step = end_step)\n","}\n","\n","# Pass in the trained baseline model\n","model_for_pruning = prune_low_magnitude(baseline_model, **pruning_params)\n","\n","# 'prune_low_magnitude' requires a recompile\n","model_for_pruning.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model_for_pruning.summary()"],"metadata":{"id":"plo19mSoCdHE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Preview model weights\n","model_for_pruning.weights[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXqCHYgMHAtc","executionInfo":{"status":"ok","timestamp":1721495293796,"user_tz":-120,"elapsed":328,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"dcae34f2-a7d4-4b33-9205-c6086169a81f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 12) dtype=float32, numpy=\n","array([[[[-0.65388936, -0.37027386, -0.5895651 ,  0.25797945,\n","           0.02541543, -0.6621699 ,  0.15978512, -0.03010637,\n","           0.26917607,  0.52216   ,  0.34164882, -0.14870733]],\n","\n","        [[-0.47334045,  0.07472505, -0.5171312 ,  0.41284287,\n","           0.23645961, -0.08986535,  0.02500086,  0.2895436 ,\n","           0.2700939 ,  0.6329086 , -0.09309151, -0.2279    ]],\n","\n","        [[-0.4112018 ,  0.26842037, -0.5538995 ,  0.6393494 ,\n","           0.1891551 ,  0.5963347 ,  0.11188681, -0.00722711,\n","           0.23119628,  0.41641408, -0.34437463, -0.00086102]]],\n","\n","\n","       [[[-0.16584733, -0.26762313, -0.10571435, -0.5680298 ,\n","           0.21757409, -0.6163616 , -0.1669713 ,  0.186569  ,\n","           0.01832947,  0.085479  ,  0.15577339,  0.28355384]],\n","\n","        [[-0.03654844,  0.09806405,  0.16673827, -0.14484172,\n","           0.04716373,  0.12461241,  0.13102461,  0.19672811,\n","           0.02712863, -0.04133146,  0.11103339,  0.20023438]],\n","\n","        [[ 0.14120941,  0.328681  , -0.14515539,  0.30541432,\n","          -0.16426258,  0.46215525,  0.14270723,  0.2344457 ,\n","          -0.00324898, -0.09920403,  0.09968734,  0.28790894]]],\n","\n","\n","       [[[-0.07203981, -0.02806057,  0.45173958, -0.31340837,\n","           0.21233736, -0.2787801 ,  0.21187766,  0.15323536,\n","          -0.09098084, -0.84325695,  0.2756794 ,  0.12331702]],\n","\n","        [[ 0.27995372,  0.26094684,  0.21815161, -0.59581894,\n","           0.25959852,  0.1884996 ,  0.2680945 , -0.11363129,\n","           0.2011892 , -0.62321466,  0.2109415 ,  0.11293191]],\n","\n","        [[ 0.44190326,  0.05550227,  0.33714676, -0.36522353,\n","          -0.09187439,  0.21125838,  0.17154132,  0.01161029,\n","           0.2885022 , -0.3665778 , -0.13968304, -0.12590814]]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# Callback to update pruning wrappers at each step\n","callbacks = [tfmot.sparsity.keras.UpdatePruningStep()]\n","\n","# Train and prune the model\n","model_for_pruning.fit(x_train, y_train, epochs=epochs, validation_split=validation_split,\n","                  callbacks=callbacks)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2P8UIDzHYvj","executionInfo":{"status":"ok","timestamp":1721495465814,"user_tz":-120,"elapsed":45834,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"69ae4e9e-fc2b-4b70-b7ef-74b212c1d3fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1688/1688 [==============================] - 24s 12ms/step - loss: 0.1459 - accuracy: 0.9601 - val_loss: 0.0963 - val_accuracy: 0.9738\n","Epoch 2/2\n","1688/1688 [==============================] - 21s 12ms/step - loss: 0.1072 - accuracy: 0.9687 - val_loss: 0.0869 - val_accuracy: 0.9770\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7834d56d0550>"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# Preview model weights after pruning (zeroing out)\n","model_for_pruning.weights[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZF7exNIH3oc","executionInfo":{"status":"ok","timestamp":1721495477651,"user_tz":-120,"elapsed":290,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"1c4b822f-ea6b-492d-e0b0-faa40cc9b1f4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 12) dtype=float32, numpy=\n","array([[[[-1.2199291 ,  0.        , -1.2455136 ,  0.        ,\n","          -0.        , -1.0761017 ,  0.        ,  0.        ,\n","           0.        ,  0.8754954 ,  0.7317014 ,  0.        ]],\n","\n","        [[-1.0470268 ,  0.        , -0.61345565,  0.67668736,\n","          -0.        , -0.        ,  0.        ,  0.        ,\n","           0.        ,  0.99224913, -0.        ,  0.        ]],\n","\n","        [[-0.        ,  0.        , -0.6936322 ,  0.9042901 ,\n","          -0.        ,  0.9175063 ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.        ]]],\n","\n","\n","       [[[ 0.        ,  0.        ,  0.        , -1.0346237 ,\n","          -0.        , -0.8650951 ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.7810932 ]],\n","\n","        [[ 0.        ,  0.        ,  0.        ,  0.        ,\n","          -0.        , -0.        ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.        ]],\n","\n","        [[ 0.        ,  0.        ,  0.        ,  0.        ,\n","          -0.        ,  0.8262459 ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.7842334 ]]],\n","\n","\n","       [[[ 0.        ,  0.        ,  0.98663896,  0.        ,\n","           0.        , -0.        ,  0.        ,  0.        ,\n","           0.        , -1.0541989 , -0.        , -0.        ]],\n","\n","        [[ 0.        ,  0.        ,  0.        , -1.1973385 ,\n","           0.        , -0.        ,  0.        , -0.        ,\n","           0.        , -0.9380787 , -0.        , -0.        ]],\n","\n","        [[ 0.9577318 ,  0.        ,  0.        ,  0.        ,\n","           0.        , -0.        ,  0.        , -0.        ,\n","           0.        ,  0.        , -0.        , -0.        ]]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["# Remove pruning wrappers\n","model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n","model_for_export.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9Qe9qgZIHuA","executionInfo":{"status":"ok","timestamp":1721495525804,"user_tz":-120,"elapsed":618,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"8769aa2b-2d8c-4923-d0e1-82382e026f18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," reshape (Reshape)           (None, 28, 28, 1)         0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 26, 12)        120       \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 13, 13, 12)        0         \n"," D)                                                              \n","                                                                 \n"," flatten (Flatten)           (None, 2028)              0         \n","                                                                 \n"," dense (Dense)               (None, 10)                20290     \n","                                                                 \n","=================================================================\n","Total params: 20410 (79.73 KB)\n","Trainable params: 20410 (79.73 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Preview model weights (index 1 earlier in 0 now because of pruning wrapper removal)\n","model_for_export.weights[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPgwwQpBIRWI","executionInfo":{"status":"ok","timestamp":1721495564585,"user_tz":-120,"elapsed":287,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"db43cac6-623e-4fdf-cf3b-a870496f06d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 12) dtype=float32, numpy=\n","array([[[[-1.2199291 ,  0.        , -1.2455136 ,  0.        ,\n","          -0.        , -1.0761017 ,  0.        ,  0.        ,\n","           0.        ,  0.8754954 ,  0.7317014 ,  0.        ]],\n","\n","        [[-1.0470268 ,  0.        , -0.61345565,  0.67668736,\n","          -0.        , -0.        ,  0.        ,  0.        ,\n","           0.        ,  0.99224913, -0.        ,  0.        ]],\n","\n","        [[-0.        ,  0.        , -0.6936322 ,  0.9042901 ,\n","          -0.        ,  0.9175063 ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.        ]]],\n","\n","\n","       [[[ 0.        ,  0.        ,  0.        , -1.0346237 ,\n","          -0.        , -0.8650951 ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.7810932 ]],\n","\n","        [[ 0.        ,  0.        ,  0.        ,  0.        ,\n","          -0.        , -0.        ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.        ]],\n","\n","        [[ 0.        ,  0.        ,  0.        ,  0.        ,\n","          -0.        ,  0.8262459 ,  0.        ,  0.        ,\n","           0.        ,  0.        , -0.        ,  0.7842334 ]]],\n","\n","\n","       [[[ 0.        ,  0.        ,  0.98663896,  0.        ,\n","           0.        , -0.        ,  0.        ,  0.        ,\n","           0.        , -1.0541989 , -0.        , -0.        ]],\n","\n","        [[ 0.        ,  0.        ,  0.        , -1.1973385 ,\n","           0.        , -0.        ,  0.        , -0.        ,\n","           0.        , -0.9380787 , -0.        , -0.        ]],\n","\n","        [[ 0.9577318 ,  0.        ,  0.        ,  0.        ,\n","           0.        , -0.        ,  0.        , -0.        ,\n","           0.        ,  0.        , -0.        , -0.        ]]]],\n","      dtype=float32)>"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["We can notice that the pruned model has the same file size as the baseline_model when saved as H5. This is to be expected. The improvement can be seen when compressing the model."],"metadata":{"id":"m_KmwR4gGA1h"}},{"cell_type":"code","source":["# Save Keras model\n","model_for_export.save(FILE_PRUNED_MODEL_H5, include_optimizer=False)\n","\n","# Get uncompressed size of baseline and pruned models\n","MODEL_SIZE = {}\n","MODEL_SIZE['baseline h5'] = os.path.getsize(FILE_NON_QUANTIZED_H5)\n","MODEL_SIZE['pruned h5'] = os.path.getsize(FILE_PRUNED_MODEL_H5)\n","\n","print_metric(MODEL_SIZE, 'model size in bytes')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YN_aSeNFIa6M","executionInfo":{"status":"ok","timestamp":1721495645488,"user_tz":-120,"elapsed":306,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"2fe902b8-42d7-47e6-ec15-3d52e059c16a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["model size in bytes for baseline h5: 98968\n","model size in bytes for pruned h5: 98968\n"]}]},{"cell_type":"markdown","source":["Compressed pruned model is about 3 times smaller than baseline."],"metadata":{"id":"xiURzG9-GR-H"}},{"cell_type":"code","source":["# Get compressed size of baseline and pruned models\n","MODEL_SIZE = {}\n","MODEL_SIZE['baseline h5'] = get_gzipped_model_size(FILE_NON_QUANTIZED_H5)\n","MODEL_SIZE['pruned non quantized h5'] = get_gzipped_model_size(FILE_PRUNED_MODEL_H5)\n","\n","print_metric(MODEL_SIZE, \"gzipped model size in bytes\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzBFzIUHIupD","executionInfo":{"status":"ok","timestamp":1721495677084,"user_tz":-120,"elapsed":310,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"ce5f59dc-4bab-4595-e106-ec69af4da983"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gzipped model size in bytes for baseline h5: 78070\n","gzipped model size in bytes for pruned non quantized h5: 25993\n"]}]},{"cell_type":"markdown","source":["We can make the model even more lighweight by quantizing the pruned model in .tflite format. This results in around 10X reduction in compressed model size as compared to the baseline."],"metadata":{"id":"ucNqCLcnGlxH"}},{"cell_type":"code","source":["# Convert and quantize the pruned model\n","pruned_quantized_tflite = convert_tflite(model_for_export, FILE_PRUNED_QUANTIZED_TFLITE, quantize=True)\n","\n","# Compress and get the model size\n","MODEL_SIZE['pruned quantized tflite'] = get_gzipped_model_size(FILE_PRUNED_QUANTIZED_TFLITE)\n","print_metric(MODEL_SIZE, \"gzipped model size in bytes\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9tCMCErI4vz","executionInfo":{"status":"ok","timestamp":1721495743353,"user_tz":-120,"elapsed":1978,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"744a7b09-02d1-4657-ea65-7fbad1f58e9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gzipped model size in bytes for baseline h5: 78070\n","gzipped model size in bytes for pruned non quantized h5: 25993\n","gzipped model size in bytes for pruned quantized tflite: 8217\n"]}]},{"cell_type":"markdown","source":["Accuracy is"],"metadata":{"id":"EM2FrI6TG6Sn"}},{"cell_type":"code","source":["# Get accuracy of pruned Keras and TF Lite models\n","ACCURACY = {}\n","\n","_, ACCURACY['pruned model h5'] = model_for_pruning.evaluate(x_test, y_test)\n","ACCURACY['pruned and quantized tflite'] = evaluate_tflite_model(FILE_PRUNED_QUANTIZED_TFLITE, x_test, y_test)\n","\n","print_metric(ACCURACY, 'accuracy')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix_IefLgJGIf","executionInfo":{"status":"ok","timestamp":1721496011316,"user_tz":-120,"elapsed":4310,"user":{"displayName":"Domagoj Planjar","userId":"14948510013433019192"}},"outputId":"f602591a-cffb-4216-81a2-260d20d8679e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 7ms/step - loss: 0.0957 - accuracy: 0.9705\n","accuracy for pruned model h5: 0.9704999923706055\n","accuracy for pruned and quantized tflite: 0.9703\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bMnxKJBgKG6s"},"execution_count":null,"outputs":[]}]}